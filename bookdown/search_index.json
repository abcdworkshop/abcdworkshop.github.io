[["index.html", "ABCD Workshop Tutorials Chapter 1 Introduction", " ABCD Workshop Tutorials ABCD Facilitators 2021-07-08 Chapter 1 Introduction This is a guide to the resources &amp; tutorials from the 2021 MDC ABCD Workshop. Check back here for updates as the workshop progresses! "],["purpose.html", "Chapter 2 Purpose", " Chapter 2 Purpose The purpose of this tutorial is to start building and strengthening foundational coding skills in R. We take a functional and active approach to learning R. We believe that the easiest way to learn R is by using R. Giving you some building blocks and suggesting some strategies for overcoming common coding obstacles will allow you to begin exploring the language. You never need to actively memorize code chunks or functions. You will become proficient naturally with many hours of practice. Therefore, the goal of this tutorial is to expose you to what R can do so that you know what tools you have at your disposal when you are later working through a problem. Today’s tutorial will cover: How to download and install R and RStudio The panes of RStudio How to create and use R Markdown Documents Arithmetic commands (Some of) the different types of variables in R What functions are and how to use them How to install and load packages and… How to import data into R At the end of this tutorial is a set of Minihacks. Minihacks are small coding exercises intended to test your knowledge of the day’s material. Note: This tutorial has been modified from labs created by Cameron Kay and Sarah Dimakis for PSY 611 (Data Analysis I; Fall 2020). "],["gs.html", "Chapter 3 Getting Started 3.1 Downloading the R Engine 3.2 Downloading RStudio", " Chapter 3 Getting Started So what is R? In the simplest possible terms, R is a programming language used for conducting analyses and producing graphics. It is substantially more flexible than GUI-based statistics programs (e.g., SPSS, LISREL) but less flexible than other programming languages. This lack of flexibility is on purpose; it allows the code to be written in a far more efficient and intuitive way than other programming languages. Only one piece of software is required to get started using the R programming language and, confusingly, it is also called R. I will refer to it here as the R Engine. The R Engine essentially allows the computer to understand the R programming language, turning your lines of text into computer operations. Unlike other popular statistics programs (e.g., SPSS, SAS), the R Engine is free. Instructions for downloading the R Engine are below. A second piece of software that is not required to use R but is nonetheless useful is RStudio. RStudio is an integrated development environment (IDE) or, in potentially overly simplistic terms, a tool that makes interacting with the R Engine easier. Instructions for downloading RStudio are also below. 3.1 Downloading the R Engine Navigate to the webpage for the Comprehensive R Archive Network (commonly referred to as CRAN). Under “Download and Install R” click the appropriate link for your operating system. For example, if you are using a Mac, you would click on Download R for (Mac) OS X. Click the link for the latest release. As of writing this, the newest package is R 4.0.2. \"Taking Off Again\" (all version nicknames are references to the Peanuts comic strip). I would click R-4.0.2.pkg to start the download. Once the file is downloaded, click on it to open it. Your operating system should guide you through the rest of the installation process. Note. The same steps are used to update the R Engine: You install a new version and replace the old version in the process. 3.2 Downloading RStudio Navigate to the webpage for the free version of RStudio. For our purposes (and for most people’s purposes) the free version of RStudio is all that you need. The available installers are listed at the bottom of the page under the header “Installers for Supported Platforms.” Select the installer for your operating system. Since I am using Windows 10, I would click RStudio 1.3.1093 - Windows 10/8/7 (64-bit). Once the file is downloaded, click on it to open it. Your operating system should guide you through the rest of the installation process. Note. To update RStudio after it is already installed, all you have to do is navigate to Help &gt; Check for Updates in the menubar. "],["rstudio.html", "Chapter 4 Features of RStudio 4.1 The Console 4.2 Source 4.3 Environment/History 4.4 Files/Plots/Packages/Help", " Chapter 4 Features of RStudio As shown in the image below, an RStudio session is split into four sections called panes: the console, the source pane, the environment/history pane, and the succinctly named files/plots/packages/help pane. 4.1 The Console In RStudio, the console is the access point to the underlying R Engine. It evaluates the code you provide it, including code called using the the source pane. You can pass commands to the R Engine by typing them in after the &gt;. Think of the Console like a texting app (or for those who grew up in the 90s, AIM). The Console is where you send messages to your friend, R, and they (sometimes) respond. Once you’ve sent a message, you can no longer edit it. And once it’s been said, you can’t take it back. 4.2 Source The source pane shows you a collection of code called a script. In R, we primarily work with R Script files (files ending in .R) or R Markdown documents (files ending in .Rmd). If the Console is your texting app, then the Source pane is where you can draft your message, edit it, make sure it comes across as friendly and not passive-aggressive, etc. These files can be saved and restored later. This is really useful if (1) you plan on spreading out your work across more than one day, (2) you want to keep track of what analyses you’ve run and the way you set up those analyses, or (3) you want to share your analysis with collaborators or readers. Perhaps one of these applies to you. You can send code from Source to the Console using Command+Enter (Mac) or Ctrl+Enter (PC). 4.3 Environment/History The environment/history pane shows, well, your environment and history. Specifically, if you have the “Environment” tab selected, you will see a list of all the variables that exist in your global environment. If you have the “History” tab selected, you will see previous commands that were passed to the R Engine. 4.4 Files/Plots/Packages/Help The final pane—the files/plots/packages/help pane–includes a number of helpful tabs. The “Files” tab shows you the files in your current working directory, the “Plots” tab shows you a preview of any plots you have created, the “Packages” tab shows you a list of the packages currently installed on your computer, and the “Help” tab is where help documentation will appear. We will discuss packages and help documentation later in this lab. "],["projects.html", "Chapter 5 Projects 5.1 Creating a new project 5.2 Adding folders to a project", " Chapter 5 Projects Whenever you start a new research project, you should create a new R Project. The R project is a working directory where your .RProj file, scripts, data, images, etc. will live. Creating a folder that contains all of the files for your new research project will keep you organized and make it easy for others to download and reproduce your work. We will open up a new project for this workshop and call it ABCD 2021. 5.1 Creating a new project In order to create a new project in RStudio, click on the R icon with the plus sign in the top left corner of RStudio. Click on New Directory -&gt; New Project. Name your new directory ABCD 2021 and store it somewhere on your computer using the Browse button. I would recommend storing it on your desktop. 5.2 Adding folders to a project Once you have a new directory, you can add folders to it. Let’s add a folder for tools. You can add a folder by clicking on New Folder in the files/plots/packages/help pane. You can nest folders within folders. For example, inside the tools folder, I want to create two more folders: a scripts folder and a data folder. "],["rmarkdown.html", "Chapter 6 R Markdown 6.1 Creating an R Markdown Document 6.2 Using an R Markdown Document 6.3 Knitting an R Markdown Document", " Chapter 6 R Markdown R Markdown allows you to integrate formatted text (like in a Word or Google Doc), code, and code output into a single document. These documents can take many forms, including: html files (like this one), which allow for some interactive components, like showing/hiding code or interactive figures, pdf files, word/rich-text-format (rtf) files, for manuscripts and more. The following section will guide you the process of creating an R Markdown document. 6.1 Creating an R Markdown Document Click on the blank piece of paper with the plus sign over it in the upper left-hand corner of RStudio. Click on R Markdown.... Enter the title of document and your name. I have chosen to title the document example. Save your RMarkdown document by clicking on File -&gt; Save. I’ll save this tools -&gt; scripts folder in my ABCD 2021 project. 6.2 Using an R Markdown Document The content of R Markdown documents can be split into two main types. I will call the first type simple text. Simple text will not be evaluated by the computer other than to be formatted according to markdown syntax. If you are describing analytic decisions or interpreting the results of an analysis, you will likely be using simple text. Note: If a comment takes up more than a line, write it in simple text, not as an R comment. Simple text can help ensure your documents are easily readable. R comments (prefaced using #) are more difficult to read and extend off the page in some Markdown formats. Markdown syntax is used to format the simple text, such as italicizing words by enclosing them in asterisks (e.g., *this is italicized* becomes this is italicized) or bolding words by enclosing them in double-asterisks (e.g., **this is bold** becomes this is bold). For a quick rundown of what you can do with R Markdown formatting, I suggest you check out the Markdown section of the R Markdown Cheat Sheet. In addition to simple text, R Markdown documents support R code using “chunks”. A chunk is a section of text that the document recognizes as code, rather than simple text. It will be set off in the final version of the document through different formatting. In contrast to simple text, the R code chunks are evaluated by the computer. The chunks are surrounded by ```{r} and ```. In the example image below, the 1 + 2 in the R Code chunk will be evaluated when the document is “knitted” (rendered). 6.3 Knitting an R Markdown Document In order to knit an R Markdown document, you can either use the shortcut command + shift + k or click the button at the top of the R Markdown document that says Knit. The computer will take several seconds (or, depending on the length of the R Markdown document, several minutes) to knit the document. Once the computer has finished knitting the document, a new document will appear in the same location that the R Markdown document is saved. In this example, the new document will end with a .html extension. As shown in the above image, the simple text in the R Markdown document on the left was rendered into a formatted in the knitted document on the right. The equation in the code chunk was also evaluated in the knitted document, returning the value 3. "],["the-basics-of-coding-in-r.html", "Chapter 7 The Basics of Coding in R 7.1 Arithmetic commands 7.2 Creating Variables 7.3 Functions 7.4 Help Documentation 7.5 Googling your error message 7.6 Comments 7.7 Packages 7.8 Importing Data into R", " Chapter 7 The Basics of Coding in R 7.1 Arithmetic commands As mentioned above, you can pass commands to the R-engine via the console. R has arithmetic commands for doing basic math operations, including addition (+), subtraction (-), multiplication (*), division (/), and exponentiation (^). R will automatically follow the PEMDAS order of operations (BEDMAS if you are from Canada or New Zealand). Parentheses can be used to tell R what parts of the equation should be evaluated first. As shown below and as expected, (10 + 5) * 2 is not equivalent to 10 + 5 * 2. 7.2 Creating Variables You can create variables using the assignment operator (&lt;-). Whatever is on the left of the assignment operator is saved to name specified on the right of the assignment operator. I like to imagine that there is a box with a name on it and you are placing a value, inside of the box. For example, if we wanted to place 10 into a variable called my_number, we would write: If we want to see what is stored in my_number, we can simply type my_number into the console and press enter. We are essentially asking the computer, “What’s in the box with my_number written on it?” If we want to overwrite my_number with a new value, we simply assign a new value to my_number. Looking at my_number again, we can see that it is now 20. We can treat variables just like we would the underlying values. For example, we can add 5 to my_number by using +. Keep in mind, the above operation does not save the result of my_number + 5 to my_number. To do that, we would have to assign the result of my_number + 5 to my_number. If we want to remove a variable from our environment, we can use rm(). 7.2.1 Types of Variables In R, there are four basic types of data: (1) logical values (also called booleans), which can either be TRUE or FALSE, (2) integer values, which can be any whole number (i.e.., a number without digits after the decimal place), (3) double values, which can be any number with digits before and after the decimal place, and (4) character values (also called strings), which are pieces of text enclosed in quotation marks (\"). Type Examples Logical/Boolean TRUE, FALSE Integer 10L, -10L Double 10.50, -10.50 Character \"Hello\", \"World\" 7.2.2 Vectors 7.2.2.1 Atomic Vectors A collection of values is called a vector. If they are all of the same type, we call them atomic vectors. In R, we use the c() command to concatenate (or combine) values into an atomic vector. Just as we did with the scalar values above, we can assign a vector to a variable. To print out the entire vector, we simply type my_vector into the console. In order to select just one value from the vector, we use square brackets ([]). For example, if we wanted the third value from my_vector we would type my_vector[3]1. If we want to replace a specific value in a vector, we use the assignment operator (&lt;-) in conjunction with the square brackets ([]). As with single-value objects we can perform arithmetic operations on vectors, but the behaviour is not identical. If the vectors are the same length, each value from one vector will be paired with a corresponding value from the other vector. See below for an example of this in action. If the vectors of different lengths, the shorter vector will be recycled (i.e., repeated) to be the same length as the longer vector. This also works when the longer vector is not a multiple of the shorter vector, but you will get the warning: longer object length is not a multiple of shorter object length. 7.2.2.1.0.1 1. Unlike most other coding languages (e.g., python), indices in R start at 1 instead of 0. For instance, if you want to select the first element of a vector, you would write my_vector[1] instead of my_vector[0]. A second difference to keep in mind is that the - is used in R to remove whichever value is in the spot indicated by the index value. Using vector[-2] on the vector c(10, 20, 30, 40, 50, 60) would return c(10, 30, 40, 50, 60) in R. In python, it would return 50. 7.2.2.2 Lists A vector that can accomodate more than one type of value (e.g., a double AND a character) is called a list. To create a list, we use list() instead of c(). If we wanted to create a vector with the values 5L, 10, \"fifteen\", and FALSE we would use list(5L, 10, \"fifteen\", FALSE). Although lists are an incredibly powerful type of data structure, dealing with them can be quite frustrating (especially for beginning coders). Since you are unlikely to need to know the inner workings of lists for anything we will be doing in this course, I have chosen not to include much about them here. However, as you become a more advanced user, learning to leverage lists will allow you to write code that is far more efficient. 7.2.3 Data Frames In R you will mostly be working with data frames. A data frame is technically a list of atomic vectors. For our purposes, we can think of a data frame as a spread sheet with columns of variables and rows of observations. Let’s look at a data frame that is automatically loaded when you open R, mtcars. Type mtcars to print out the data frame. The data frame mtcars has a row for 32 cars featured in the 1974 Motor Trend magazine. There is a column for the car’s miles per gallon (mpg), number of cylinders (cyl), engine displacement (disp), horse power (hp), rear axle ratio (drat), weight in thousands of pounds (wt), quarter-mile time (qsec), engine shape (vs), transmission type (am), number of forward gears (gear), and number of carburetors (carb). With data frames, you can extract a value by including [row, col] immediately after the object. For example, if we wanted to extract the number of gears in the Datsun 710 we could use mtcars[3, 10] to extract the value stored in the third row, tenth column. Since the rows and columns have names, we can also be explicit and use the name of the row (\"Datsun 710\") and the name of the column (\"gear\") instead of the row and column indices. We can also extract an entire column by dropping the index value for the row. Since you don’t specify a given row, the computer assumes you want all of the values in the column. For example, to extract all values stored in the gear column, we could use [, 10] or [, \"gear\"]. To extract an entire row, we drop the column index. To extract all of the values associated with the Datsun 710, we would drop the column index (e.g., [3, ] or [\"Datsun 710\", ]) You can also extract columns using $ followed by the column name without quotes. If we want to extract multiple columns (or multiple rows) we use vectors. For example, if we wanted the number of gears and carburetors in the Datsun 710 and the Duster 360 we would use [c(\"Datsun 710\", \"Duster 360\"), c(\"gear\", \"carb\")] or [c(3, 7), c(10:11)]. 7.3 Functions Up to this point, we have been more-or-less directly telling R what we want it to do. This is great if we want to understand the processes that underlie R, but it can be incredibly time-consuming. Thankfully, we have functions. Functions are essentially pre-packaged snippets of code that take one or more pieces of input (called arguments) and return one or more pieces of output (called values). For example, length() is a function that takes a vector as its sole argument and returns the length of the vector as its sole value. The function unique() also takes a vector as its primary argument, but—instead of returning the length of the vector as its value—it returns only the unique values of that vector. The mean() function and sd() function are two functions that you will end up using a lot. The former (mean()) takes a numeric vector and returns the average of the vector. The latter (sd()) also takes a numeric vector, but it returns the standard deviation of the vector instead. Although it is more conceptual, it is also useful to mention the typeof() function here. The function typeof() takes any object and tells you what type of variable it is. Using the suite of as.*() functions (e.g., as.numeric(), as.character(), as.logical(), as.integer()), we can likewise coerce objects to other types. 7.4 Help Documentation Sometimes when working in R you will want to know more about a function. For example, you might want to know what arguments the function sd() takes. You can use ? at the beginning of any function call to display the help documentation for that function. From the help documentation we can see that sd() takes two arguments: (1) An R object and (2) a logical value indicating whether NAs (unknown values) should be removed before the standard deviation is calculated. Typically R will infer, based on the order of the arguments, what values correspond to which arguments. For example, since sd() expects that the argument x will be provided first and the argument na.rm will be provided second, the following works: However, we can also explicitly tell R what values are associated with which arguments. The help documentation for a function often also includes an example of how to use the function and details on what the expected output will be. 7.5 Googling your error message You will come across many messages in your time using RStudio. Some messages are error messages and some are warning messages. If a message says warning message then R was able to run the code but not as it was intended. An error message means that R was not able to run the code at all. Here is an example of code that would produce a warning message. mean(c(4,5,&quot;6&quot;,7,5)) When you get a warning or error message, and you aren’t sure what it means, you should first try googling the message. Oftentimes, others have encountered your problem and have asked for help deciphering the message. Scott from Stack overflow suggests converting the character “6” into a numeric variable. Let’s try that. mean(c(4,5,as.numeric(&quot;6&quot;),7,5)) ## [1] 5.4 7.6 Comments Comments are pieces of code text that are not interpreted by the computer. In R we use the octothorpe/pound sign/hashtag (#) at the beginning of a line to denote a comment. The first and third line of code below are not evaluated, whereas the second and fourth line are. Comments are mostly used to remind yourself (or other people) what a piece of code does and why the code is written the way that it is. Below is a piece of code that checks if a string is a valid phone number. We can see that the comments explain, not only what each piece of code is doing, but also why the second piece of code was written the way that it was. 7.7 Packages A package can include code, documentation for that code, and/or data. A helpful way to think of packages is as a toolbox full of data analysis tools. There are general purpose toolboxes that contain tools for running common analyses in psychology (e.g., psych), toolboxes for helping your run advanced statistical models (e.g., lavaan; lmer), toolboxes for text mining (e.g., tidytext), and toolboxes for plotting (e.g., ggplot2, gganimate). If you have a problem that needs to be solved, there will probably be a package for it. 7.7.1 Installing packages Let’s say you’re gardeniing for the first time, and you need a hoe to clear some weeds. If you’ve never gardenend before, you don’t have a hoe lying around your house. You’ll need to go to your local hardware store and buy one. This is the idea behind “installing” a package – you’ve never used it before, so you’ll need to download it from CRAN (which is analagous to a Home Depot) or maybe a private repo (like going to a local mom ’n pop store). Once you’ve bought your hoe (or downloaded your package), it lives at your house (on your computer) and you don’t need to buy it (download it) again… unless someone builds a better version and you want to upgrade. To install a package onto your computer, you simply pass the name of the package to install.packages(). As a demonstration, we install the psych package below. The psych package has several useful data analysis tools for psychologists. Note. When installing packages, the package name must be enclosed in quotes: install.packages(\"psych\") NOT install.packages(psych). You generally only need to install a package once. 7.7.2 Loading a package Your hoe lives in your tool shed most of the time, but you need to get it out when you want to garden. This is like “loading” a package. Just because we’ve installed a package to our computer doesn’t mean we have access to its functions. Buying a toolbox doesn’t necessarily give you access to its tools. You also have to open the toolbox. To open psych and load its functions, we use library(). Note. A package can be loaded with or without quotes: library(\"psych\") OR library(psych). We have to load a package every time that R is restarted. 7.7.3 Try psych commands Now that we have installed and loaded the psych package, let’s try out of some its commands. Using corr.test() we can make a correlation matrix of the variables in mtcars. Using skew(), we can look at the skew of all of the columns in mtcars. We can also use t2d() to calculate the Cohen’s d for a t-value of 3.00 with 300 participants. This is only a small subset of the functions available in the psych package, and psych is only one package of over 11,000 on CRAN (as of 2018). This is not to mention the tens of thousands of packages hosted on online repositories like GitHub. As Cory Costello noted during R Bootcamp, the question with R is never if but how. 7.8 Importing Data into R The final topic that we will cover in this lab is how to load data into R. Over the course of your careers (and many times in this workshop) you will need to import data into R to be analyzed. For this example, we will be using the planets data set from Star Wars. The data can be downloaded here. You can use file-type-specific functions to load data into R (e.g., read.csv, read_excel). However, the rio package streamlines this process by having a single import function (import()) that infers the file type from its extension (e.g., .csv, .xlsx, .sav). Additionally, the here package makes it very easy to reference folders in your directory. As we did for psych, if you don’t have these packages already, you will first need to install rio and here. You can install rio and here with the following code: install.packages(c(\"rio\", \"here\")). Second, we will need to load rio and here using the library functions. Then, we will import the data by using the import function from the rio package and the here function from the here package. In order to use the here function, we need to know which folder my dataset is saved in. In this case, the sw_planets.xlsx is saved in labs -&gt; data. Finally, we will save the data into a variable, planets_data. To ensure it was read in properly, we can look at the first six rows of the imported dataset by using the head() function. We can also look at the last six rows by using the tail() function. "],["minihacks.html", "Chapter 8 Minihacks 8.1 Minihack 1: R Markdown 8.2 Minihack 2: Arithmetic Commands 8.3 Minihack 3: Functions 8.4 Minihack 4: Help Documentation 8.5 Minihack 5: Data Frames", " Chapter 8 Minihacks Minihacks are practice problems for you to challenge yourself and learn the material more deeply. Give them a shot! 8.1 Minihack 1: R Markdown Create an R Markdown document called minihacks. Save it in your tools -&gt; scripts folder. Try rendering your R Markdown document by clicking knit. If it doesn’t render correctly, try to figure out why it didn’t. 8.2 Minihack 2: Arithmetic Commands Use R to calculate \\(\\frac{(102 + 68) \\times (3 + 2) + 1250}{50}\\) and assign the result to a variable called x. Assign the numbers 10, 20, and 30 to a vector called y. Before running any code, determine what you think adding x to y would result in. Then, using R, add x to y. 8.3 Minihack 3: Functions Assign the string \"I AM NOT YELLING\" to a variable called exclamation. Use the function tolower() to convert every letter of exclamation to lower case. Assign the result to exclamation. Use the capitalize() function from the Hmisc package to capitalize the first letter of exclamation. 8.4 Minihack 4: Help Documentation I wanted to create a vector of 5 values between 10 and 50 using seq(), but the code I wrote is creating a vector of 9 values between 10 and 50. I believe it has something to do with the arguments I used, but I can’t remember how to access the help documention to check. Without changing the values (i.e., 10, 50, and 5), can you fix my code? seq(from = 10, to = 50, by = 5) ## [1] 10 15 20 25 30 35 40 45 50 8.5 Minihack 5: Data Frames Download the Marvel character dataset to your computer. Put the data file in your tools -&gt; data folder. Import the data into R and assign it to a variable called marvel_data. Ah! The value for the number of appearances of Spider-Man seems to be an error! It should be 4043 not 40430! Use square brackets ([]) to replace the erroneous value with the correct value (hint: The value is stored in the first row of the eighth column). Using mean() and dollar sign notation (data$column), calculate the average number of appearances for all of the Marvel characters. Assign the result to a variable called mean_appearances. Install and load the package ggplot2. If you succesfully completed the proceeding steps, you should be able to run the following code without producing an error. If you get an error, try to figure out why you are receiving the error. ggplot(marvel_data, aes(x = reorder(align, -appearances), y = appearances, fill = align)) + geom_bar(stat = &quot;summary&quot;, fun.y = &quot;mean&quot;) + geom_point(shape = 21, alpha = .7, position = position_jitter(w = 0.4, h = 0)) + geom_hline(yintercept = mean_appearances, linetype = &quot;twodash&quot;, lwd = 1, colour = &quot;firebrick&quot;) + annotate(geom = &quot;text&quot;, x = 3, y = 800, size = 5, label = paste(&quot;Mean = &quot;, round(mean_appearances, 2)), colour = &quot;firebrick&quot;) + scale_fill_viridis_d() + theme_bw(base_size = 15) + theme(legend.position = &quot;none&quot;) + labs(title = &quot;Alignment and Appearances&quot;, subtitle = &quot;Marvel character appearances by alignment&quot;, x = &quot;Alignment&quot;, y = &quot;Appearances&quot;) "],["mdc-abcd-workshop-2021-multilevel-model-track-1-tutorial.html", "Chapter 9 MDC ABCD Workshop 2021 Multilevel Model Track 1 Tutorial", " Chapter 9 MDC ABCD Workshop 2021 Multilevel Model Track 1 Tutorial 9.0.1 Load some ABCD data 9.0.2 Visualize longitudinal study design # Reclass variables in Demographics datatable, and filter to only relevant variables for this section abcddemo_tbl &lt;- abcddemo %&gt;% filter(!sex==&quot;Sex of the subject&quot;) %&gt;% select(interview_age, src_subject_id, eventname, sex, demo_gender_id_v2_l) %&gt;% mutate(interview_age=as.integer(interview_age), src_subject_id=as.factor(src_subject_id), eventname=as.factor(eventname), sex=as.factor(sex), gender=as.factor(demo_gender_id_v2_l)) # Filter to a subsample for easier visualization random_rows &lt;- sample(2000) abcddemo_tbl &lt;- abcddemo_tbl[random_rows, ] study_design &lt;- abcddemo_tbl[order(abcddemo_tbl$interview_age, abcddemo_tbl$src_subject_id, abcddemo_tbl$eventname),] %&gt;% mutate(Rank_nr=as.numeric(factor(src_subject_id,levels=unique(src_subject_id)))) study_design_plot&lt;- ggplot(study_design, aes(x=(interview_age/12), y=Rank_nr, group=src_subject_id, shape=sex, col=gender)) + geom_point(alpha=1) + geom_line(alpha=.4) + ylab(&quot;&quot;) + xlab(&quot;Age (years)&quot;) + scale_y_discrete(breaks=NULL) + theme_kate()+ theme(axis.text.y = element_blank()) # Take a look print(study_design_plot) ggsave(filename=&quot;abcd_study_design.png&quot;, plot=study_design_plot, width=6, height=5, units=&#39;in&#39;, dpi=300) #Print biological sex histogram sex_histogram &lt;- ggplot(abcddemo_tbl,aes(x=interview_age,fill=sex))+ scale_fill_manual(aes(fill=sex), labels = c(&quot;female&quot;, &quot;male&quot;), values = c(&quot;#FDE74C&quot;, &quot;#56A3A6&quot;)) + geom_histogram(alpha=1, position=&quot;stack&quot;,binwidth=1) + xlim(min(abcddemo_tbl$interview_age),max(abcddemo_tbl$interview_age)) + ggtitle(&quot;&quot;) + guides(fill=guide_legend(title=&quot;Sex&quot;))+ ylab(&quot;N&quot;) + xlab(&quot;Interview age in months&quot;)+ theme_kate() sex_histogram ## Warning: Removed 4 rows containing missing values (geom_bar). ggsave(filename=&quot;abcd_sex_histogram.png&quot;, plot=sex_histogram, width=6, height=5, units=&#39;in&#39;, dpi=300) ## Warning: Removed 4 rows containing missing values (geom_bar). 9.0.3 Let’s visualize some of the ABCD dataset # Take a look at the variables—rio didn&#39;t do a good job classifying them correctly. str(abcdbrief) ## &#39;data.frame&#39;: 31319 obs. of 42 variables: ## $ collection_id : chr &quot;collection_id&quot; &quot;2573&quot; &quot;2573&quot; &quot;2573&quot; ... ## $ abcd_yssbpm01_id : chr &quot;abcd_yssbpm01_id&quot; &quot;15499&quot; &quot;15504&quot; &quot;15522&quot; ... ## $ dataset_id : chr &quot;dataset_id&quot; &quot;34403&quot; &quot;34403&quot; &quot;34403&quot; ... ## $ subjectkey : chr &quot;The NDAR Global Unique Identifier (GUID) for research subject&quot; &quot;NDAR_INV00BD7VDC&quot; &quot;NDAR_INV00CY2MDM&quot; &quot;NDAR_INV00UMK5VC&quot; ... ## $ src_subject_id : chr &quot;Subject ID how it&#39;s defined in lab/project&quot; &quot;NDAR_INV00BD7VDC&quot; &quot;NDAR_INV00CY2MDM&quot; &quot;NDAR_INV00UMK5VC&quot; ... ## $ interview_date : chr &quot;Date on which the interview/genetic test/sampling/imaging/biospecimen was completed. MM/DD/YYYY&quot; &quot;04/24/2019&quot; &quot;01/13/2020&quot; &quot;09/25/2019&quot; ... ## $ interview_age : chr &quot;Age in months at the time of the interview/test/sampling/imaging.&quot; &quot;123&quot; &quot;158&quot; &quot;132&quot; ... ## $ sex : chr &quot;Sex of the subject&quot; &quot;M&quot; &quot;M&quot; &quot;F&quot; ... ## $ eventname : chr &quot;The event name for which the data was collected&quot; &quot;1_year_follow_up_y_arm_1&quot; &quot;30_month_follow_up_arm_1&quot; &quot;1_year_follow_up_y_arm_1&quot; ... ## $ bpm_y_scr_attention_r : chr &quot;Raw Score: bpm_1_y plus bpm_3_y plus bpm_4_y plus bpm_5_y plus bpm_10_y plus bpm_14_y; Validation: All items must be answered&quot; &quot;3.0&quot; &quot;0.0&quot; &quot;7.0&quot; ... ## $ bpm_y_scr_attention_t : chr &quot;T-Score&quot; &quot;53.0&quot; &quot;50.0&quot; &quot;68.0&quot; ... ## $ bpm_y_scr_attention_nm : chr &quot;Number Missing Answers&quot; &quot;0.0&quot; &quot;0.0&quot; &quot;0.0&quot; ... ## $ bpm_y_scr_attention_nt : chr &quot;Number Total Questions&quot; &quot;6.0&quot; &quot;6.0&quot; &quot;6.0&quot; ... ## $ bpm_y_ss_attention_mean: chr &quot;Mean Score: Mean(bpm_1_y plus bpm_3_y plus bpm_4_y plus bpm_5_y plus bpm_10_y plus bpm_14_y); Validation: All i&quot;| __truncated__ &quot;0.5&quot; &quot;0.0&quot; &quot;1.1666666666666667&quot; ... ## $ bpm_y_ss_attention_nm : chr &quot;Number Missing Answers&quot; &quot;0.0&quot; &quot;0.0&quot; &quot;0.0&quot; ... ## $ bpm_y_ss_attention_nt : chr &quot;Number Total Questions&quot; &quot;6.0&quot; &quot;6.0&quot; &quot;6.0&quot; ... ## $ bpm_y_scr_internal_r : chr &quot;Raw Score: bpm_2_y plus bpm_6_y plus bpm_7_y plus bpm_8_y plus bpm_15_y plus bpm_16_y plus bpm_17_y; Validation&quot;| __truncated__ &quot;4.0&quot; &quot;0.0&quot; &quot;8.0&quot; ... ## $ bpm_y_scr_internal_t : chr &quot;T-Score&quot; &quot;62.0&quot; &quot;50.0&quot; &quot;68.0&quot; ... ## $ bpm_y_scr_internal_nm : chr &quot;Number Missing Answers&quot; &quot;0.0&quot; &quot;0.0&quot; &quot;0.0&quot; ... ## $ bpm_y_scr_internal_nt : chr &quot;Number Total Questions&quot; &quot;6.0&quot; &quot;6.0&quot; &quot;6.0&quot; ... ## $ bpm_y_ss_internal_mean : chr &quot;Mean Score: Mean(bpm_2_y plus bpm_6_y plus bpm_7_y plus bpm_8_y plus bpm_15_y plus bpm_16_y plus bpm_17_y); Val&quot;| __truncated__ &quot;0.6666666666666666&quot; &quot;0.0&quot; &quot;1.3333333333333333&quot; ... ## $ bpm_y_ss_internal_nm : chr &quot;Number Missing Answers&quot; &quot;0.0&quot; &quot;0.0&quot; &quot;0.0&quot; ... ## $ bpm_y_ss_internal_nt : chr &quot;Number Total Questions&quot; &quot;6.0&quot; &quot;6.0&quot; &quot;6.0&quot; ... ## $ bpm_y_scr_external_r : chr &quot;Raw Score: bpm_9_y plus bpm_11_y plus bpm_12_y plus bpm_13_y plus bpm_18_y plus bpm_19_y; Validation: All items&quot;| __truncated__ &quot;3.0&quot; &quot;0.0&quot; &quot;3.0&quot; ... ## $ bpm_y_scr_external_t : chr &quot;T-Score&quot; &quot;51.0&quot; &quot;50.0&quot; &quot;51.0&quot; ... ## $ bpm_y_scr_external_nm : chr &quot;Number Missing Answers&quot; &quot;0.0&quot; &quot;0.0&quot; &quot;0.0&quot; ... ## $ bpm_y_scr_external_nt : chr &quot;Number Total Questions&quot; &quot;7.0&quot; &quot;7.0&quot; &quot;7.0&quot; ... ## $ bpm_y_ss_external_mean : chr &quot;Mean Score: Mean(bpm_9_y plus bpm_11_y plus bpm_12_y plus bpm_13_y plus bpm_18_y plus bpm_19_y); Validation: Al&quot;| __truncated__ &quot;0.42857142857142855&quot; &quot;0.0&quot; &quot;0.42857142857142855&quot; ... ## $ bpm_y_ss_external_nm : chr &quot;Number Missing Answers&quot; &quot;0.0&quot; &quot;0.0&quot; &quot;0.0&quot; ... ## $ bpm_y_ss_external_nt : chr &quot;Number Total Questions&quot; &quot;7.0&quot; &quot;7.0&quot; &quot;7.0&quot; ... ## $ bpm_y_scr_totalprob_r : chr &quot;Raw Score: bpm_1_y plus bpm_2_y plus bpm_3_y plus bpm_4_y plus bpm_5_y plus bpm_6_y plus bpm_7_y plus bpm_8_y p&quot;| __truncated__ &quot;10.0&quot; &quot;0.0&quot; &quot;18.0&quot; ... ## $ bpm_y_scr_totalprob_t : chr &quot;T-Score&quot; &quot;57.0&quot; &quot;50.0&quot; &quot;66.0&quot; ... ## $ bpm_y_scr_totalprob_nm : chr &quot;Number Missing Answers&quot; &quot;0.0&quot; &quot;0.0&quot; &quot;0.0&quot; ... ## $ bpm_y_scr_totalprob_nt : chr &quot;Number Total Questions&quot; &quot;19.0&quot; &quot;19.0&quot; &quot;19.0&quot; ... ## $ bpm_y_ss_totalprob_mean: chr &quot;Mean: Mean(bpm_1_y plus bpm_2_y plus bpm_3_y plus bpm_4_y plus bpm_5_y plus bpm_6_y plus bpm_7_y plus bpm_8_y p&quot;| __truncated__ &quot;0.5263157894736842&quot; &quot;0.0&quot; &quot;0.9473684210526316&quot; ... ## $ bpm_y_ss_totalprob_nm : chr &quot;Number Missing Answers&quot; &quot;0.0&quot; &quot;0.0&quot; &quot;0.0&quot; ... ## $ bpm_y_ss_totalprob_nt : chr &quot;Number Total Questions&quot; &quot;19.0&quot; &quot;19.0&quot; &quot;19.0&quot; ... ## $ poa_y_ss_sum : chr &quot;NIH Toolbox Positive Affect; Sum(poa_nihtb_1_y plus poa_nihtb_2_yplus poa_nihtb_3_y plus poa_nihtb_4_y plus po&quot;| __truncated__ &quot;23.0&quot; &quot;24.0&quot; &quot;15.0&quot; ... ## $ poa_y_ss_sum_nm : chr &quot;Number Missing Answers&quot; &quot;0.0&quot; &quot;0.0&quot; &quot;0.0&quot; ... ## $ poa_y_ss_sum_nt : chr &quot;Number Total Questions&quot; &quot;9.0&quot; &quot;9.0&quot; &quot;9.0&quot; ... ## $ collection_title : chr &quot;collection_title&quot; &quot;Adolescent Brain Cognitive Development Study (ABCD)&quot; &quot;Adolescent Brain Cognitive Development Study (ABCD)&quot; &quot;Adolescent Brain Cognitive Development Study (ABCD)&quot; ... ## $ study_cohort_name : chr &quot;study_cohort_name&quot; &quot;ABCD 3.0 Data Release&quot; &quot;ABCD 3.0 Data Release&quot; &quot;ABCD 3.0 Data Release&quot; ... # Reclassify relevant variables abcdbrief &lt;- abcdbrief %&gt;% filter(!sex==&quot;Sex of the subject&quot;) %&gt;% mutate(interview_age=as.integer(interview_age), src_subject_id=as.factor(src_subject_id), eventname=as.factor(eventname), sex=as.factor(sex), bpm_internal=as.numeric(bpm_y_ss_internal_mean), bpm_exteral=as.numeric(bpm_y_ss_external_mean) ) # Filter to a subsample for easier visualization random_rows &lt;- sample(2000) abcdbrief_short &lt;- abcdbrief[random_rows, ] # Let&#39;s just take a look at this variable over time abcdbrief_plot&lt;-ggplot(data=abcdbrief_short, aes(x=interview_age/12, y=bpm_internal))+ xlim(min(abcdbrief$interview_age/12),max(abcdbrief$interview_age/12))+ ylim(min(abcdbrief$bpm_internal),max(abcdbrief$bpm_internal))+ xlab(&quot;Age (years)&quot;)+ ylab(&quot;Brief Internalizing (mean)&quot;)+ ggtitle(&quot;Brief Internalizing by Age&quot;)+ geom_line(aes(colour=sex, group=src_subject_id), size=.6, alpha=0.4)+ geom_point(aes(colour=sex, group=src_subject_id), size=1.5, alpha=0.5)+ scale_color_manual(name= &quot;sex&quot;, labels = c(&quot;female&quot;, &quot;male&quot;), values = c(&quot;#FDE74C&quot;, &quot;#56A3A6&quot;))+ theme_kate()+ theme(legend.position=&quot;none&quot;) # Take a look print(abcdbrief_plot) ## Warning: Removed 15 row(s) containing missing values (geom_path). ## Warning: Removed 15 rows containing missing values (geom_point). 9.0.4 Let’s dive into some modeling # Load the dataset in the tutorial load(&quot;braindata.Rdata&quot;) # Check out variable classifications str(braindata) ## &#39;data.frame&#39;: 274 obs. of 20 variables: ## $ subid : num 84292 84292 84292 85244 85244 ... ## $ scanid : num 19660681 19680105 19690701 19670303 19690383 ... ## $ scannum : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 2 3 1 2 1 2 1 2 3 ... ## $ age : num 18 20 21 18 20 18 21 18 20 21 ... ## $ sex : Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 1 1 1 1 1 1 1 2 2 2 ... ## $ prefrontal_vol_long : num 163943 163082 159252 146655 142802 ... ## $ prefrontal_vol_cross : num 161681 161585 160965 140177 141758 ... ## $ amygdala_vol_long : num 3611 3682 3560 3572 3604 ... ## $ amygdala_vol_cross : num 3648 3812 3569 3489 3379 ... ## $ caudate_vol_long : num 8756 8540 8407 7934 7917 ... ## $ caudate_vol_cross : num 7895 7968 7945 7322 7367 ... ## $ hippocampus_vol_long : num 9345 9120 9079 7892 7631 ... ## $ hippocampus_vol_cross: num 8905 9021 8799 7864 7350 ... ## $ nacc_vol_long : num 1396 1445 1442 1417 1462 ... ## $ nacc_vol_cross : num 1204 1256 1239 1168 1187 ... ## $ thalamus_vol_long : num 15948 15783 15876 15864 15822 ... ## $ thalamus_vol_cross : num 15234 15083 15777 15258 15460 ... ## $ putamen_vol_long : num 12182 11873 11808 12021 11591 ... ## $ putamen_vol_cross : num 11310 11030 11249 10908 10797 ... ## $ motion : int 1 1 1 1 1 1 1 1 1 1 ... # Fix a variable classification braindata&lt;-braindata %&gt;% mutate(subid=as.factor(subid)) # Create age-centered variable to reduce correlations between age and polynomial terms braindata&lt;-braindata %&gt;% mutate(agecent=age-(mean(age))) # Create polynomial terms to examine non-linear group models braindata&lt;-braindata %&gt;% mutate(agecentsq=agecent*agecent, agecentcu=agecent*agecent*agecent) # Create unconditional model using nlme package (lme function) uncond_PFCmodel=lme(prefrontal_vol_long ~ 1, method=&quot;ML&quot;, random = ~1|subid, data=braindata) # Create unconditional model using lme4 package (lmer function) uncond_PFCmodel_lmer=lmer(prefrontal_vol_long ~ 1 + (1 | subid), REML = FALSE, data=braindata) ## Linear age model (nlme) lin_PFCmodel=lme(prefrontal_vol_long ~ agecent, method=&quot;ML&quot;, random = ~1|subid, data=braindata) ## Linear age model (lme4) lin_PFCmodel_lmer=lmer(prefrontal_vol_long ~ agecent + (1 | subid), REML = FALSE, data=braindata) # Take a look at the fixed effects coefficient fixef(lin_PFCmodel) ## (Intercept) agecent ## 167750.369 -2323.406 fixef(lin_PFCmodel_lmer) ## (Intercept) agecent ## 167750.369 -2323.406 # Now take a look at the random effects coefficients coef(lin_PFCmodel) ## (Intercept) agecent ## 80796 155714.7 -2323.406 ## 80804 152915.0 -2323.406 ## 80828 181501.5 -2323.406 ## 80964 154999.6 -2323.406 ## 81028 173129.6 -2323.406 ## 81980 192268.0 -2323.406 ## 82828 158364.2 -2323.406 ## 83308 171642.2 -2323.406 ## 84100 177579.3 -2323.406 ## 84116 183780.2 -2323.406 ## 84124 176993.8 -2323.406 ## 84156 187290.7 -2323.406 ## 84260 181683.0 -2323.406 ## 84292 169548.4 -2323.406 ## 84372 159533.7 -2323.406 ## 84412 139096.2 -2323.406 ## 84444 177101.8 -2323.406 ## 84508 142623.5 -2323.406 ## 84564 169383.9 -2323.406 ## 84588 157338.4 -2323.406 ## 84596 149221.3 -2323.406 ## 84612 176743.7 -2323.406 ## 84668 172685.2 -2323.406 ## 84676 181819.9 -2323.406 ## 84684 174647.4 -2323.406 ## 84732 146216.6 -2323.406 ## 84796 151139.1 -2323.406 ## 84804 163450.4 -2323.406 ## 84812 184301.8 -2323.406 ## 84868 200256.2 -2323.406 ## 84876 195899.0 -2323.406 ## 84900 177357.3 -2323.406 ## 84908 207327.3 -2323.406 ## 84916 188703.3 -2323.406 ## 84948 143658.9 -2323.406 ## 84956 167123.4 -2323.406 ## 84964 180644.1 -2323.406 ## 84996 161255.2 -2323.406 ## 85004 173915.9 -2323.406 ## 85020 140818.0 -2323.406 ## 85092 161158.5 -2323.406 ## 85172 152332.5 -2323.406 ## 85180 156115.3 -2323.406 ## 85204 165541.3 -2323.406 ## 85244 150937.7 -2323.406 ## 85252 160302.7 -2323.406 ## 85284 182671.9 -2323.406 ## 85316 149586.0 -2323.406 ## 85556 190716.0 -2323.406 ## 85572 169434.3 -2323.406 ## 85636 152704.5 -2323.406 ## 85644 150847.9 -2323.406 ## 85660 149879.9 -2323.406 ## 85668 148180.3 -2323.406 ## 85676 159704.4 -2323.406 ## 85700 140191.7 -2323.406 ## 85708 162332.5 -2323.406 ## 85724 143842.9 -2323.406 ## 85756 194529.2 -2323.406 ## 85764 160492.2 -2323.406 ## 85772 179342.8 -2323.406 ## 85820 200818.8 -2323.406 ## 85868 163833.2 -2323.406 ## 85884 169087.5 -2323.406 ## 85900 147774.8 -2323.406 ## 85948 149199.8 -2323.406 ## 85956 154255.4 -2323.406 ## 85964 142429.3 -2323.406 ## 85996 181676.3 -2323.406 ## 86012 141919.7 -2323.406 ## 86020 183444.9 -2323.406 ## 86028 170891.8 -2323.406 ## 86044 152281.7 -2323.406 ## 86052 198136.2 -2323.406 ## 86068 186011.3 -2323.406 ## 86076 179367.1 -2323.406 ## 86084 176666.9 -2323.406 ## 86092 147098.0 -2323.406 ## 86116 181259.8 -2323.406 ## 86124 154543.4 -2323.406 ## 86140 176715.2 -2323.406 ## 86148 155906.1 -2323.406 ## 86156 167181.9 -2323.406 ## 86172 184302.3 -2323.406 ## 86188 147502.7 -2323.406 ## 86292 179197.6 -2323.406 ## 86300 192151.2 -2323.406 ## 86308 178068.4 -2323.406 ## 86324 151649.0 -2323.406 ## 86340 182247.4 -2323.406 ## 86356 145823.0 -2323.406 ## 86372 154547.7 -2323.406 ## 86380 176326.6 -2323.406 ## 86388 158167.3 -2323.406 ## 86396 170707.2 -2323.406 ## 86532 183811.3 -2323.406 ## 86548 187074.7 -2323.406 ## 86556 188814.7 -2323.406 ## 86564 176288.1 -2323.406 ## 86612 174468.7 -2323.406 ## 86620 184098.6 -2323.406 ## 86628 141290.9 -2323.406 ## 86676 160735.2 -2323.406 coef(lin_PFCmodel_lmer) ## $subid ## (Intercept) agecent ## 80796 155714.7 -2323.406 ## 80804 152915.0 -2323.406 ## 80828 181501.5 -2323.406 ## 80964 154999.6 -2323.406 ## 81028 173129.6 -2323.406 ## 81980 192268.0 -2323.406 ## 82828 158364.2 -2323.406 ## 83308 171642.2 -2323.406 ## 84100 177579.3 -2323.406 ## 84116 183780.2 -2323.406 ## 84124 176993.8 -2323.406 ## 84156 187290.7 -2323.406 ## 84260 181683.0 -2323.406 ## 84292 169548.4 -2323.406 ## 84372 159533.7 -2323.406 ## 84412 139096.2 -2323.406 ## 84444 177101.8 -2323.406 ## 84508 142623.5 -2323.406 ## 84564 169383.9 -2323.406 ## 84588 157338.4 -2323.406 ## 84596 149221.3 -2323.406 ## 84612 176743.7 -2323.406 ## 84668 172685.2 -2323.406 ## 84676 181819.9 -2323.406 ## 84684 174647.4 -2323.406 ## 84732 146216.6 -2323.406 ## 84796 151139.1 -2323.406 ## 84804 163450.4 -2323.406 ## 84812 184301.8 -2323.406 ## 84868 200256.2 -2323.406 ## 84876 195899.0 -2323.406 ## 84900 177357.3 -2323.406 ## 84908 207327.3 -2323.406 ## 84916 188703.3 -2323.406 ## 84948 143658.9 -2323.406 ## 84956 167123.4 -2323.406 ## 84964 180644.1 -2323.406 ## 84996 161255.2 -2323.406 ## 85004 173915.9 -2323.406 ## 85020 140818.0 -2323.406 ## 85092 161158.5 -2323.406 ## 85172 152332.5 -2323.406 ## 85180 156115.3 -2323.406 ## 85204 165541.3 -2323.406 ## 85244 150937.7 -2323.406 ## 85252 160302.7 -2323.406 ## 85284 182671.9 -2323.406 ## 85316 149586.0 -2323.406 ## 85556 190716.0 -2323.406 ## 85572 169434.3 -2323.406 ## 85636 152704.5 -2323.406 ## 85644 150847.9 -2323.406 ## 85660 149879.9 -2323.406 ## 85668 148180.3 -2323.406 ## 85676 159704.4 -2323.406 ## 85700 140191.7 -2323.406 ## 85708 162332.5 -2323.406 ## 85724 143842.9 -2323.406 ## 85756 194529.2 -2323.406 ## 85764 160492.2 -2323.406 ## 85772 179342.8 -2323.406 ## 85820 200818.8 -2323.406 ## 85868 163833.2 -2323.406 ## 85884 169087.5 -2323.406 ## 85900 147774.8 -2323.406 ## 85948 149199.8 -2323.406 ## 85956 154255.4 -2323.406 ## 85964 142429.3 -2323.406 ## 85996 181676.3 -2323.406 ## 86012 141919.7 -2323.406 ## 86020 183444.9 -2323.406 ## 86028 170891.8 -2323.406 ## 86044 152281.7 -2323.406 ## 86052 198136.2 -2323.406 ## 86068 186011.3 -2323.406 ## 86076 179367.1 -2323.406 ## 86084 176666.9 -2323.406 ## 86092 147098.0 -2323.406 ## 86116 181259.8 -2323.406 ## 86124 154543.4 -2323.406 ## 86140 176715.2 -2323.406 ## 86148 155906.1 -2323.406 ## 86156 167181.9 -2323.406 ## 86172 184302.3 -2323.406 ## 86188 147502.7 -2323.406 ## 86292 179197.6 -2323.406 ## 86300 192151.2 -2323.406 ## 86308 178068.4 -2323.406 ## 86324 151649.0 -2323.406 ## 86340 182247.4 -2323.406 ## 86356 145823.0 -2323.406 ## 86372 154547.7 -2323.406 ## 86380 176326.6 -2323.406 ## 86388 158167.3 -2323.406 ## 86396 170707.2 -2323.406 ## 86532 183811.3 -2323.406 ## 86548 187074.7 -2323.406 ## 86556 188814.7 -2323.406 ## 86564 176288.1 -2323.406 ## 86612 174468.7 -2323.406 ## 86620 184098.6 -2323.406 ## 86628 141290.9 -2323.406 ## 86676 160735.2 -2323.406 ## ## attr(,&quot;class&quot;) ## [1] &quot;coef.mer&quot; #Slightly different print(coef(lin_PFCmodel)-coef(lin_PFCmodel_lmer)) ## (Intercept).(Intercept) (Intercept).agecent agecent.(Intercept) ## 80796 0.00000077174627 158038.1 -158038.1 ## 80804 0.00000130629633 155238.4 -155238.4 ## 80828 -0.00000083274790 183824.9 -183824.9 ## 80964 0.00000083839404 157323.0 -157323.0 ## 81028 -0.00000045265188 175453.0 -175453.0 ## 81980 -0.00000159442425 194591.4 -194591.4 ## 82828 0.00000061682658 160687.6 -160687.6 ## 83308 -0.00000038955477 173965.6 -173965.6 ## 84100 -0.00000080341124 179902.7 -179902.7 ## 84116 -0.00000135030132 186103.6 -186103.6 ## 84124 -0.00000047401409 179317.2 -179317.2 ## 84156 -0.00000108632958 189614.1 -189614.1 ## 84260 -0.00000080050086 184006.4 -184006.4 ## 84292 -0.00000000759610 171871.8 -171871.8 ## 84372 0.00000062270556 161857.1 -161857.1 ## 84412 0.00000186747639 141419.6 -141419.6 ## 84444 -0.00000049159280 179425.2 -179425.2 ## 84508 0.00000157015165 144946.9 -144946.9 ## 84564 -0.00000002124580 171707.3 -171707.3 ## 84588 0.00000058294972 159661.8 -159661.8 ## 84596 0.00000171657302 151544.7 -151544.7 ## 84612 -0.00000042558531 179067.1 -179067.1 ## 84668 -0.00000032398384 175008.6 -175008.6 ## 84676 -0.00000098347664 184143.3 -184143.3 ## 84684 -0.00000056691351 176970.8 -176970.8 ## 84732 0.00000121421181 148540.1 -148540.1 ## 84796 0.00000145597733 153462.5 -153462.5 ## 84804 0.00000025442569 165773.8 -165773.8 ## 84812 -0.00000100815669 186625.2 -186625.2 ## 84868 -0.00000205123797 202579.6 -202579.6 ## 84876 -0.00000187652768 198222.4 -198222.4 ## 84900 -0.00000063853804 179680.7 -179680.7 ## 84908 -0.00000374621595 209650.7 -209650.7 ## 84916 -0.00000122937490 191026.7 -191026.7 ## 84948 0.00000213881140 145982.3 -145982.3 ## 84956 0.00000007616472 169446.8 -169446.8 ## 84964 -0.00000072453986 182967.5 -182967.5 ## 84996 0.00000041382737 163578.7 -163578.7 ## 85004 -0.00000033568358 176239.3 -176239.3 ## 85020 0.00000171599095 143141.5 -143141.5 ## 85092 0.00000051804818 163481.9 -163481.9 ## 85172 0.00000098365126 154655.9 -154655.9 ## 85180 0.00000072491821 158438.7 -158438.7 ## 85204 0.00000014534453 167864.7 -167864.7 ## 85244 0.00000165379606 153261.1 -153261.1 ## 85252 0.00000077864388 162626.1 -162626.1 ## 85284 -0.00000139322947 184995.3 -184995.3 ## 85316 0.00000100306352 151909.4 -151909.4 ## 85556 -0.00000149721745 193039.4 -193039.4 ## 85572 -0.00000021851156 171757.7 -171757.7 ## 85636 0.00000073501724 155027.9 -155027.9 ## 85644 0.00000091266702 153171.3 -153171.3 ## 85660 0.00000102823833 152203.3 -152203.3 ## 85668 0.00000133112189 150503.7 -150503.7 ## 85676 0.00000085082138 162027.8 -162027.8 ## 85700 0.00000183153315 142515.1 -142515.1 ## 85708 0.00000047721551 164655.9 -164655.9 ## 85724 0.00000233307946 146166.3 -146166.3 ## 85756 -0.00000264769187 196852.6 -196852.6 ## 85764 0.00000038527651 162815.6 -162815.6 ## 85772 -0.00000076292781 181666.2 -181666.2 ## 85820 -0.00000215196633 203142.2 -203142.2 ## 85868 0.00000039412407 166156.6 -166156.6 ## 85884 -0.00000002607703 171410.9 -171410.9 ## 85900 0.00000175414607 150098.3 -150098.3 ## 85948 0.00000120181357 151523.2 -151523.2 ## 85956 0.00000084153726 156578.8 -156578.8 ## 85964 0.00000150597771 144752.7 -144752.7 ## 85996 -0.00000117000309 183999.7 -183999.7 ## 86012 0.00000235013431 144243.1 -144243.1 ## 86020 -0.00000085635111 185768.3 -185768.3 ## 86028 -0.00000047130743 173215.2 -173215.2 ## 86044 0.00000104145147 154605.1 -154605.1 ## 86052 -0.00000202757656 200459.6 -200459.6 ## 86068 -0.00000183546217 188334.7 -188334.7 ## 86076 -0.00000074267155 181690.5 -181690.5 ## 86084 -0.00000092966366 178990.3 -178990.3 ## 86092 0.00000120259938 149421.4 -149421.4 ## 86116 -0.00000124494545 183583.2 -183583.2 ## 86124 0.00000108900713 156866.8 -156866.8 ## 86140 -0.00000088542583 179038.6 -179038.6 ## 86148 0.00000092916889 158229.6 -158229.6 ## 86156 -0.00000012107193 169505.3 -169505.3 ## 86172 -0.00000112812268 186625.7 -186625.7 ## 86188 0.00000122078927 149826.1 -149826.1 ## 86292 -0.00000065576751 181521.0 -181521.0 ## 86300 -0.00000229536090 194474.6 -194474.6 ## 86308 -0.00000086537329 180391.8 -180391.8 ## 86324 0.00000135952723 153972.4 -153972.4 ## 86340 -0.00000140236807 184570.8 -184570.8 ## 86356 0.00000136974268 148146.4 -148146.4 ## 86372 0.00000089945388 156871.1 -156871.1 ## 86380 -0.00000056304270 178650.0 -178650.0 ## 86388 0.00000070541864 160490.7 -160490.7 ## 86396 -0.00000004746835 173030.6 -173030.6 ## 86532 -0.00000149969128 186134.7 -186134.7 ## 86548 -0.00000191852450 189398.1 -189398.1 ## 86556 -0.00000118179014 191138.1 -191138.1 ## 86564 -0.00000056062709 178611.5 -178611.5 ## 86612 -0.00000061030732 176792.1 -176792.1 ## 86620 -0.00000117000309 186422.0 -186422.0 ## 86628 0.00000250650919 143614.3 -143614.3 ## 86676 0.00000064057531 163058.6 -163058.6 ## agecent.agecent ## 80796 -0.00000003308605 ## 80804 -0.00000003308605 ## 80828 -0.00000003308605 ## 80964 -0.00000003308605 ## 81028 -0.00000003308605 ## 81980 -0.00000003308605 ## 82828 -0.00000003308605 ## 83308 -0.00000003308605 ## 84100 -0.00000003308605 ## 84116 -0.00000003308605 ## 84124 -0.00000003308605 ## 84156 -0.00000003308605 ## 84260 -0.00000003308605 ## 84292 -0.00000003308605 ## 84372 -0.00000003308605 ## 84412 -0.00000003308605 ## 84444 -0.00000003308605 ## 84508 -0.00000003308605 ## 84564 -0.00000003308605 ## 84588 -0.00000003308605 ## 84596 -0.00000003308605 ## 84612 -0.00000003308605 ## 84668 -0.00000003308605 ## 84676 -0.00000003308605 ## 84684 -0.00000003308605 ## 84732 -0.00000003308605 ## 84796 -0.00000003308605 ## 84804 -0.00000003308605 ## 84812 -0.00000003308605 ## 84868 -0.00000003308605 ## 84876 -0.00000003308605 ## 84900 -0.00000003308605 ## 84908 -0.00000003308605 ## 84916 -0.00000003308605 ## 84948 -0.00000003308605 ## 84956 -0.00000003308605 ## 84964 -0.00000003308605 ## 84996 -0.00000003308605 ## 85004 -0.00000003308605 ## 85020 -0.00000003308605 ## 85092 -0.00000003308605 ## 85172 -0.00000003308605 ## 85180 -0.00000003308605 ## 85204 -0.00000003308605 ## 85244 -0.00000003308605 ## 85252 -0.00000003308605 ## 85284 -0.00000003308605 ## 85316 -0.00000003308605 ## 85556 -0.00000003308605 ## 85572 -0.00000003308605 ## 85636 -0.00000003308605 ## 85644 -0.00000003308605 ## 85660 -0.00000003308605 ## 85668 -0.00000003308605 ## 85676 -0.00000003308605 ## 85700 -0.00000003308605 ## 85708 -0.00000003308605 ## 85724 -0.00000003308605 ## 85756 -0.00000003308605 ## 85764 -0.00000003308605 ## 85772 -0.00000003308605 ## 85820 -0.00000003308605 ## 85868 -0.00000003308605 ## 85884 -0.00000003308605 ## 85900 -0.00000003308605 ## 85948 -0.00000003308605 ## 85956 -0.00000003308605 ## 85964 -0.00000003308605 ## 85996 -0.00000003308605 ## 86012 -0.00000003308605 ## 86020 -0.00000003308605 ## 86028 -0.00000003308605 ## 86044 -0.00000003308605 ## 86052 -0.00000003308605 ## 86068 -0.00000003308605 ## 86076 -0.00000003308605 ## 86084 -0.00000003308605 ## 86092 -0.00000003308605 ## 86116 -0.00000003308605 ## 86124 -0.00000003308605 ## 86140 -0.00000003308605 ## 86148 -0.00000003308605 ## 86156 -0.00000003308605 ## 86172 -0.00000003308605 ## 86188 -0.00000003308605 ## 86292 -0.00000003308605 ## 86300 -0.00000003308605 ## 86308 -0.00000003308605 ## 86324 -0.00000003308605 ## 86340 -0.00000003308605 ## 86356 -0.00000003308605 ## 86372 -0.00000003308605 ## 86380 -0.00000003308605 ## 86388 -0.00000003308605 ## 86396 -0.00000003308605 ## 86532 -0.00000003308605 ## 86548 -0.00000003308605 ## 86556 -0.00000003308605 ## 86564 -0.00000003308605 ## 86612 -0.00000003308605 ## 86620 -0.00000003308605 ## 86628 -0.00000003308605 ## 86676 -0.00000003308605 # Summary of models summary(lin_PFCmodel) ## Linear mixed-effects model fit by maximum likelihood ## Data: braindata ## AIC BIC logLik ## 5633.229 5647.682 -2812.615 ## ## Random effects: ## Formula: ~1 | subid ## (Intercept) Residual ## StdDev: 16693.86 3057.588 ## ## Fixed effects: prefrontal_vol_long ~ agecent ## Value Std.Error DF t-value p-value ## (Intercept) 167750.37 1661.7734 170 100.94659 0 ## agecent -2323.41 141.3133 170 -16.44153 0 ## Correlation: ## (Intr) ## agecent 0.007 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.01902160 -0.48365525 0.01745049 0.49701984 2.37181597 ## ## Number of Observations: 274 ## Number of Groups: 103 summary(lin_PFCmodel_lmer) ## Linear mixed model fit by maximum likelihood [&#39;lmerMod&#39;] ## Formula: prefrontal_vol_long ~ agecent + (1 | subid) ## Data: braindata ## ## AIC BIC logLik deviance df.resid ## 5633.2 5647.7 -2812.6 5625.2 270 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.01902 -0.48366 0.01745 0.49702 2.37182 ## ## Random effects: ## Groups Name Variance Std.Dev. ## subid (Intercept) 278685115 16694 ## Residual 9348845 3058 ## Number of obs: 274, groups: subid, 103 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 167750.4 1655.7 101.3 ## agecent -2323.4 140.8 -16.5 ## ## Correlation of Fixed Effects: ## (Intr) ## agecent 0.007 ## Let&#39;s add a random slope to the model to make it an unconditional growth model lin_PFCmodel_rs=lme(prefrontal_vol_long ~ agecent, method=&quot;ML&quot;, random = ~1+agecent|subid, data=braindata) lin_PFCmodel_rs_lmer=lmer(prefrontal_vol_long ~ agecent + (agecent | subid), REML = FALSE, data=braindata) # Summary of models summary(lin_PFCmodel_rs) ## Linear mixed-effects model fit by maximum likelihood ## Data: braindata ## AIC BIC logLik ## 5633.539 5655.218 -2810.77 ## ## Random effects: ## Formula: ~1 + agecent | subid ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 16670.9877 (Intr) ## agecent 786.1584 -0.054 ## Residual 2766.3925 ## ## Fixed effects: prefrontal_vol_long ~ agecent ## Value Std.Error DF t-value p-value ## (Intercept) 167758.95 1668.4400 170 100.54838 0 ## agecent -2328.61 154.4948 170 -15.07245 0 ## Correlation: ## (Intr) ## agecent -0.018 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.831741446 -0.471641155 0.009997165 0.456398316 2.400944924 ## ## Number of Observations: 274 ## Number of Groups: 103 summary(lin_PFCmodel_rs_lmer) ## Linear mixed model fit by maximum likelihood [&#39;lmerMod&#39;] ## Formula: prefrontal_vol_long ~ agecent + (agecent | subid) ## Data: braindata ## ## AIC BIC logLik deviance df.resid ## 5633.5 5655.2 -2810.8 5621.5 268 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.83176 -0.47164 0.00999 0.45640 2.40097 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## subid (Intercept) 277920576 16671.0 ## agecent 618133 786.2 -0.05 ## Residual 7652752 2766.4 ## Number of obs: 274, groups: subid, 103 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 167759.0 1662.3 100.92 ## agecent -2328.6 153.9 -15.13 ## ## Correlation of Fixed Effects: ## (Intr) ## agecent -0.018 # Compare models with and without random slopes included anova(lin_PFCmodel,lin_PFCmodel_rs) ## Model df AIC BIC logLik Test L.Ratio p-value ## lin_PFCmodel 1 4 5633.229 5647.682 -2812.615 ## lin_PFCmodel_rs 2 6 5633.539 5655.218 -2810.770 1 vs 2 3.689881 0.158 anova(lin_PFCmodel_lmer,lin_PFCmodel_rs_lmer) ## Data: braindata ## Models: ## lin_PFCmodel_lmer: prefrontal_vol_long ~ agecent + (1 | subid) ## lin_PFCmodel_rs_lmer: prefrontal_vol_long ~ agecent + (agecent | subid) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## lin_PFCmodel_lmer 4 5633.2 5647.7 -2812.6 5625.2 ## lin_PFCmodel_rs_lmer 6 5633.5 5655.2 -2810.8 5621.5 3.6899 2 0.158 9.0.5 Modeling continued — checking out non-linear group-level trajectories ## Quadratic age model (nlme) quad_PFCmodel=lme(prefrontal_vol_long ~ agecent+agecentsq, method=&quot;ML&quot;, random = ~1|subid, data=braindata) ## Quadratic age model (lme4) quad_PFCmodel_lmer=lmer(prefrontal_vol_long ~ agecent+agecentsq+ (1 | subid), REML = FALSE, data=braindata) ## Cubic age model cub_PFCmodel=lme(prefrontal_vol_long ~ agecent+agecentsq+agecentcu, method=&quot;ML&quot;, random = ~1|subid, data=braindata) ## Cubic age model (lme4() cub_PFCmodel_lmer=lmer(prefrontal_vol_long ~ agecent+agecentsq+agecentcu+ (1 | subid), REML = FALSE, data=braindata) ## Using a model fit approach # Compare model fit using anova age_predict_PFC_table&lt;-anova(uncond_PFCmodel, lin_PFCmodel, quad_PFCmodel, cub_PFCmodel) # take a look age_predict_PFC_table ## Model df AIC BIC logLik Test L.Ratio p-value ## uncond_PFCmodel 1 3 5803.174 5814.014 -2898.587 ## lin_PFCmodel 2 4 5633.229 5647.682 -2812.615 1 vs 2 171.94548 &lt;.0001 ## quad_PFCmodel 3 5 5635.092 5653.157 -2812.546 2 vs 3 0.13714 0.7111 ## cub_PFCmodel 4 6 5627.968 5649.647 -2807.984 3 vs 4 9.12345 0.0025 # The lme4 output should look the same anova(uncond_PFCmodel_lmer, lin_PFCmodel_lmer, quad_PFCmodel_lmer, cub_PFCmodel_lmer) ## Data: braindata ## Models: ## uncond_PFCmodel_lmer: prefrontal_vol_long ~ 1 + (1 | subid) ## lin_PFCmodel_lmer: prefrontal_vol_long ~ agecent + (1 | subid) ## quad_PFCmodel_lmer: prefrontal_vol_long ~ agecent + agecentsq + (1 | subid) ## cub_PFCmodel_lmer: prefrontal_vol_long ~ agecent + agecentsq + agecentcu + (1 | ## cub_PFCmodel_lmer: subid) ## npar AIC BIC logLik deviance Chisq Df ## uncond_PFCmodel_lmer 3 5803.2 5814.0 -2898.6 5797.2 ## lin_PFCmodel_lmer 4 5633.2 5647.7 -2812.6 5625.2 171.9455 1 ## quad_PFCmodel_lmer 5 5635.1 5653.2 -2812.6 5625.1 0.1371 1 ## cub_PFCmodel_lmer 6 5628.0 5649.6 -2808.0 5616.0 9.1235 1 ## Pr(&gt;Chisq) ## uncond_PFCmodel_lmer ## lin_PFCmodel_lmer &lt; 0.00000000000000022 *** ## quad_PFCmodel_lmer 0.711136 ## cub_PFCmodel_lmer 0.002524 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #compare cubic model and linear model age_predict_PFC_linvscub_table&lt;-anova(lin_PFCmodel,cub_PFCmodel) age_predict_PFC_linvscub_table ## Model df AIC BIC logLik Test L.Ratio p-value ## lin_PFCmodel 1 4 5633.229 5647.682 -2812.615 ## cub_PFCmodel 2 6 5627.968 5649.647 -2807.984 1 vs 2 9.260595 0.0098 # Looks like the cubic model is the best fit bestagemodel_PFC&lt;-cub_PFCmodel # Graph PFC group-level polynomial model # Need to create a dataframe of predicted values for ages contained within the sample agecent&lt;-round(seq(min(braindata$agecent,na.rm = TRUE), max(braindata$agecent,na.rm = TRUE),by=1), 2) agecentsq=agecent*agecent agecentcu=agecent*agecent*agecent data.pred = data.frame(agecent=agecent, agecentsq=agecentsq, agecentcu=agecentcu) data.pred$age&lt;-(data.pred$agecent+mean(braindata$age)) y.pred = predict(bestagemodel_PFC, data.pred, level=0) data.pred = cbind.data.frame(data.pred, y.pred) scale = 1.96 designmat&lt;-model.matrix(eval(eval(bestagemodel_PFC$call$fixed)[-2]), data.pred[-3]) #make design matrix SDvalue&lt;-sqrt(diag(designmat %*% bestagemodel_PFC$varFix %*% t(designmat))) #calculate standard deviation for each point for each model y.lower&lt;-y.pred-(scale*SDvalue) #calculate confidence intervals - lower y.upper&lt;-y.pred+(scale*SDvalue) #calculate confidence intervals - upper data.pred = cbind.data.frame(data.pred, y.lower, y.upper) data.pred$prefrontal_vol_long&lt;-data.pred$y.pred # Graph it PFC_Age&lt;-ggplot(data=braindata, aes(x=age, y=prefrontal_vol_long))+ xlim(9,23)+ ylim(125000,225000)+ xlab(&quot;Age (years)&quot;)+ ylab(&quot;PFC volume (longitudinal)&quot;)+ geom_line(data=data.pred, aes(x=age, y=prefrontal_vol_long), size=.7, colour=&quot;deeppink&quot;)+ geom_ribbon(data=data.pred, aes(ymin=y.lower, ymax=y.upper), alpha=0.2, fill=&quot;deeppink&quot;)+ geom_line(aes(colour=subid, group=subid),size=.3,alpha=0.3)+ geom_point(aes(colour=subid, group=subid),size=2,alpha=0.3)+ theme_kate() + theme(legend.position=&quot;none&quot;) print(PFC_Age) 9.0.6 Let’s try a GAMM approach # Model a penalized cubic regression spline of with 4 knots gamm4_pfc&lt;-gamm(prefrontal_vol_long ~ s(age,bs = &quot;cs&quot;,k=4), random=list(subid=~1), data=(braindata)) summary(gamm4_pfc$gam) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## prefrontal_vol_long ~ s(age, bs = &quot;cs&quot;, k = 4) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 167748 1653 101.5 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(age) 2.8 3 96.32 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.169 ## Scale est. = 9.0152e+06 n = 274 # Create a predicted age data frame for graphing age&lt;-round(seq(min(braindata$age,na.rm = TRUE), max(braindata$age,na.rm = TRUE),by=1),2) data.pred = data.frame(age=age) y.pred = predict(gamm4_pfc$gam, newdata=data.pred,se=T) data.pred = cbind.data.frame(data.pred, y.pred) scale = 1.96 y.upper = y.pred$fit + (scale*y.pred$se.fit) y.lower = y.pred$fit - (scale*y.pred$se.fit) prefrontal_vol_long&lt;-data.pred$fit assign(&quot;gamm4_pfc_pred&quot;,cbind.data.frame(data.pred, y.lower, y.upper, prefrontal_vol_long)) rm(avgage,data.pred,y.pred,y.upper,y.lower) ## Warning in rm(avgage, data.pred, y.pred, y.upper, y.lower): object &#39;avgage&#39; not ## found # Graph it gamm4_pfc_plot&lt;-ggplot(data=NULL, aes(x=age, y=prefrontal_vol_long))+ ylab(&quot;Prefrontal Volume&quot;)+ xlab(&quot;Age (years)&quot;)+ geom_line(data=braindata, aes(group=subid, colour=subid), alpha=0.4, size=.6) + geom_point(data=braindata, aes(colour=sex), size=1.5, alpha=0.5) + geom_line(data=gamm4_pfc_pred, aes(x=age, y=prefrontal_vol_long), size=1, colour=&quot;purple2&quot;)+ geom_ribbon(data=gamm4_pfc_pred, aes(ymin=y.lower, ymax=y.upper), alpha=0.4, fill=&quot;purple2&quot;)+ theme_kate()+ theme(legend.position=&quot;none&quot;) print(gamm4_pfc_plot) 9.0.7 Looking at models for different groups # Create a gamm with sex interacting on age gamm_fullsexint_pfc&lt;- gamm(prefrontal_vol_long ~ sex + s(age,bs = &quot;cs&quot;,k=4) + s(age,by=sex,k=4), random=list(subid=~1), data=(braindata)) # Just main effects of sex gamm_mainsexint_pfc&lt;- gamm(prefrontal_vol_long ~ sex + s(age,bs = &quot;cs&quot;,k=4), random=list(subid=~1), data=(braindata)) # Age only model gamm_ageonly_pfc&lt;- gamm(prefrontal_vol_long ~ s(age,bs = &quot;cs&quot;,k=4), random=list(subid=~1), data=(braindata)) # Compare the models modcompare&lt;-anova(gamm_ageonly_pfc$lme, gamm_mainsexint_pfc$lme, gamm_fullsexint_pfc$lme) print(modcompare) ## Model df AIC BIC logLik Test L.Ratio ## gamm_ageonly_pfc$lme 1 4 5636.487 5650.940 -2814.244 ## gamm_mainsexint_pfc$lme 2 5 5565.088 5583.154 -2777.544 1 vs 2 73.39918 ## gamm_fullsexint_pfc$lme 3 9 5556.884 5589.402 -2769.442 2 vs 3 16.20391 ## p-value ## gamm_ageonly_pfc$lme ## gamm_mainsexint_pfc$lme &lt;.0001 ## gamm_fullsexint_pfc$lme 0.0028 summary(gamm_fullsexint_pfc$gam) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## prefrontal_vol_long ~ sex + s(age, bs = &quot;cs&quot;, k = 4) + s(age, ## by = sex, k = 4) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 154939 1692 91.57 &lt;0.0000000000000002 *** ## sexM 23969 2316 10.35 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(age) 0.00000001813 2.000 0.00 0.298 ## s(age):sexF 1.00000047193 1.000 143.06 &lt;0.0000000000000002 *** ## s(age):sexM 2.88801786929 2.888 69.44 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.606 ## Scale est. = 8.3408e+06 n = 274 # And with the lme/lmer polynomial approach ## Cubic age model with sex as an interaction (nlme) sexint_PFCmodel=lme(prefrontal_vol_long ~ agecent*sex+agecentsq*sex+agecentcu*sex, method=&quot;ML&quot;, random = ~1|subid, data=braindata) ## Cubic age model with sex as an interaction (lme4) sexint_PFCmodel_lmer=lmer(prefrontal_vol_long ~ agecent*sex+agecentsq*sex+agecentcu*sex + (1 | subid), REML = FALSE, data=braindata) summary(sexint_PFCmodel) ## Linear mixed-effects model fit by maximum likelihood ## Data: braindata ## AIC BIC logLik ## 5550.953 5587.084 -2765.476 ## ## Random effects: ## Formula: ~1 | subid ## (Intercept) Residual ## StdDev: 11521.95 2891.856 ## ## Fixed effects: prefrontal_vol_long ~ agecent * sex + agecentsq * sex + agecentcu * sex ## Value Std.Error DF t-value p-value ## (Intercept) 154509.41 1746.2265 165 88.48188 0.0000 ## agecent -2382.25 291.3240 165 -8.17732 0.0000 ## sexM 24984.57 2388.1770 101 10.46177 0.0000 ## agecentsq 49.67 41.1480 165 1.20708 0.2291 ## agecentcu 3.97 10.2486 165 0.38708 0.6992 ## agecent:sexM -887.75 406.9756 165 -2.18134 0.0306 ## sexM:agecentsq -107.20 52.5106 165 -2.04149 0.0428 ## sexM:agecentcu 31.31 13.1850 165 2.37456 0.0187 ## Correlation: ## (Intr) agecnt sexM agcnts agcntc agcn:M sxM:gcnts ## agecent 0.032 ## sexM -0.731 -0.023 ## agecentsq -0.205 -0.181 0.150 ## agecentcu -0.032 -0.744 0.023 0.249 ## agecent:sexM -0.023 -0.716 0.020 0.129 0.533 ## sexM:agecentsq 0.161 0.142 -0.202 -0.784 -0.195 -0.107 ## sexM:agecentcu 0.025 0.578 -0.013 -0.194 -0.777 -0.753 0.125 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.919346794 -0.441999400 -0.003820263 0.504183581 2.575966492 ## ## Number of Observations: 274 ## Number of Groups: 103 summary(sexint_PFCmodel_lmer) ## Linear mixed model fit by maximum likelihood [&#39;lmerMod&#39;] ## Formula: prefrontal_vol_long ~ agecent * sex + agecentsq * sex + agecentcu * ## sex + (1 | subid) ## Data: braindata ## ## AIC BIC logLik deviance df.resid ## 5551.0 5587.1 -2765.5 5531.0 264 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.91935 -0.44200 -0.00382 0.50418 2.57597 ## ## Random effects: ## Groups Name Variance Std.Dev. ## subid (Intercept) 132755265 11522 ## Residual 8362833 2892 ## Number of obs: 274, groups: subid, 103 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 154509.414 1720.545 89.803 ## agecent -2382.249 287.040 -8.299 ## sexM 24984.569 2353.055 10.618 ## agecentsq 49.669 40.543 1.225 ## agecentcu 3.967 10.098 0.393 ## agecent:sexM -887.753 400.990 -2.214 ## sexM:agecentsq -107.200 51.738 -2.072 ## sexM:agecentcu 31.308 12.991 2.410 ## ## Correlation of Fixed Effects: ## (Intr) agecnt sexM agcnts agcntc agcn:M sxM:gcnts ## agecent 0.032 ## sexM -0.731 -0.023 ## agecentsq -0.205 -0.181 0.150 ## agecentcu -0.032 -0.744 0.023 0.249 ## agecent:sxM -0.023 -0.716 0.020 0.129 0.533 ## sexM:gcntsq 0.161 0.142 -0.202 -0.784 -0.195 -0.107 ## sexM:agcntc 0.025 0.578 -0.013 -0.194 -0.777 -0.753 0.125 ## Cubic age model with sex as a main effect (nlme) sexmain_PFCmodel=lme(prefrontal_vol_long ~ agecent+agecentsq+agecentcu+sex, method=&quot;ML&quot;, random = ~1|subid, data=braindata) ## Cubic age model with sex as a main effect (lme4) sexmain_PFCmodel_lmer=lmer(prefrontal_vol_long ~ agecent+agecentsq+agecentcu+sex + (1 | subid), REML = FALSE, data=braindata) # Compare the models as well as to the age-only model anova(cub_PFCmodel,sexmain_PFCmodel,sexint_PFCmodel) ## Model df AIC BIC logLik Test L.Ratio p-value ## cub_PFCmodel 1 6 5627.968 5649.647 -2807.984 ## sexmain_PFCmodel 2 7 5556.557 5581.849 -2771.279 1 vs 2 73.41100 &lt;.0001 ## sexint_PFCmodel 3 10 5550.953 5587.084 -2765.476 2 vs 3 11.60476 0.0089 9.0.8 Graph models for different groups females&lt;-braindata %&gt;% filter(sex==&quot;F&quot;) assign(paste0(&quot;gammmod_female_pfc&quot;), gamm(prefrontal_vol_long ~ s(age,bs = &quot;cs&quot;,k=4), random=list(subid=~1), data=(females))) summary(get(paste0(&quot;gammmod_female_pfc&quot;))$gam) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## prefrontal_vol_long ~ s(age, bs = &quot;cs&quot;, k = 4) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 154907 1650 93.88 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(age) 2.41 3 60.98 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.231 ## Scale est. = 6.4612e+06 n = 128 age&lt;-round(seq(min(females$age,na.rm = TRUE), max(females$age,na.rm = TRUE),by=1),2) data.pred = data.frame(age=age) y.pred = predict(get(paste0(&quot;gammmod_female_pfc&quot;))$gam, newdata=data.pred,se=T) data.pred = cbind.data.frame(data.pred, y.pred) scale = 1.96 y.upper = y.pred$fit + (scale*y.pred$se.fit) y.lower = y.pred$fit - (scale*y.pred$se.fit) prefrontal_vol_long&lt;-data.pred$fit assign(paste0(&quot;pred_females_pfc&quot;),cbind.data.frame(data.pred, y.lower, y.upper, prefrontal_vol_long)) rm(avgage,data.pred,y.pred,y.upper,y.lower) ## Warning in rm(avgage, data.pred, y.pred, y.upper, y.lower): object &#39;avgage&#39; not ## found males&lt;-braindata %&gt;% filter(sex==&quot;M&quot;) assign(paste0(&quot;gammmod_male_pfc&quot;), gamm(prefrontal_vol_long ~ s(age,bs = &quot;cs&quot;,k=4), random=list(subid=~1), data=(males))) summary(get(paste0(&quot;gammmod_male_pfc&quot;))$gam) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## prefrontal_vol_long ~ s(age, bs = &quot;cs&quot;, k = 4) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 178967 1616 110.8 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(age) 2.832 3 56.33 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.347 ## Scale est. = 1.0114e+07 n = 146 avgage&lt;-round(seq(min(males$age,na.rm = TRUE), max(males$age,na.rm = TRUE),by=1),2) data.pred = data.frame(age=age) y.pred = predict(get(paste0(&quot;gammmod_male_pfc&quot;))$gam, newdata=data.pred,se=T) data.pred = cbind.data.frame(data.pred, y.pred) scale = 1.96 y.upper = y.pred$fit + (scale*y.pred$se.fit) y.lower = y.pred$fit - (scale*y.pred$se.fit) prefrontal_vol_long&lt;-data.pred$fit assign(paste0(&quot;pred_males_pfc&quot;),cbind.data.frame(data.pred, y.lower, y.upper,prefrontal_vol_long)) # Graph it pfcbysex&lt;-ggplot(data=NULL, aes(x=age, y=prefrontal_vol_long))+ ylab(&quot;Prefrontal Cortex Volume&quot;)+ xlab(&quot;Age (years)&quot;)+ scale_color_manual(name= &quot;Sex&quot;, labels = c(&quot;female&quot;, &quot;male&quot;), values = c(&quot;#FDE74C&quot;, &quot;#56A3A6&quot;)) + geom_point(data=braindata, aes(colour=sex), size=1.5, alpha=0.6) + geom_line(data=get(paste0(&quot;pred_males_pfc&quot;)), aes(x=age, y=prefrontal_vol_long), size=1, colour=&quot;#56A3A6&quot;)+ geom_ribbon(data=get(paste0(&quot;pred_males_pfc&quot;)), aes(ymin=y.lower, ymax=y.upper), alpha=0.4, fill=&quot;#56A3A6&quot;)+ geom_line(data=get(paste0(&quot;pred_females_pfc&quot;)), aes(x=age, y=prefrontal_vol_long), size=1, colour=&quot;#FDE74C&quot;)+ geom_ribbon(data=get(paste0(&quot;pred_females_pfc&quot;)), aes(ymin=y.lower, ymax=y.upper), alpha=0.4, fill=&quot;#FDE74C&quot;)+ theme_kate() ggsave(filename=&quot;pfcbysexgamm.png&quot;, plot=pfcbysex, width=6, height=4, units=&#39;in&#39;, dpi=300) "],["references.html", "References", " References "]]
